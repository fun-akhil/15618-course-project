<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>N Moving Body Simulation - 15618 Project Proposal</title>
</head>
<body>
    <h1>15618 Project: N moving body simulation</h1>
    <p><strong>Team members:</strong> Akhil Kashyap and Ashwin Nayak Ullal</p>
    <p><strong>Website URL:</strong> <a href="https://quantum109678.github.io/15618-course-project/" target="_blank">https://quantum109678.github.io/15618-course-project/</a></p>
    <h3>SUMMARY:</h3>
    <p>We are going to implement the N body simulation, where we simulate the movement of N bodies/particles in a 2 dimensional space under the influence of gravitational force using Pthreads, OpenMP and MPI. We will compare the Speedup achieved using these 3 approaches.</p>
    <h3>BACKGROUND:</h3>
    <p>The N-body simulation is a classic computational physics problem in which the objective is to predict the individual motions of a group of celestial objects interacting with each other gravitationally. Each body exerts a force on all others, influencing their acceleration, velocity, and ultimately, their position over time. This problem scales quadratically with the number of bodies (N^2), as every body interacts with every other body, making it computationally intensive, especially for large values of N.</p>
    <p>The simulation involves calculating the gravitational forces between all pairs of bodies, updating their velocities and positions, and iterating this process over discrete time steps. The computationally demanding nature of this task makes it an ideal candidate for parallelization.</p>
    <p>Parallelism can be exploited in several ways: by distributing the computation of forces among processors, by parallelizing the update of body attributes, or by doing both concurrently. The goal of parallelizing the N-body simulation is to reduce the overall computation time by dividing the work among multiple processing elements. In shared-memory systems, threads can be created via Pthreads or OpenMP to perform calculations concurrently, with OpenMP providing a higher-level, often simpler, abstraction for parallelism. Message Passing Interface (MPI) is used for distributed-memory systems where data is passed between processes running on different nodes of a cluster. Hybrid approaches can combine MPI with OpenMP to leverage both distributed and shared memory models, and for highly parallel architectures like GPUs, CUDA can be utilized to perform massive amounts of calculations in parallel.</p>
    <p>The N-body simulation's inherent lack of data dependency during the force calculation phase makes it particularly amenable to parallel processing. Each body's new state can be computed independently based on a common, unchanging snapshot of the system. This characteristic allows for the distribution of the simulation across multiple computational units without the need for synchronization during the calculation phase, thus providing a significant opportunity for performance gains through parallelism. The speedup and efficiency of parallel implementations can be measured by comparing the execution time to that of a sequential algorithm, particularly as the number of bodies and the computational resources vary.</p>
    <p><strong>Project Proposal link:</strong> <a href="https://github.com/quantum109678/15618-course-project/blob/main/docs/Project%20proposal.pdf" target="_blank">https://github.com/quantum109678/15618-course-project/blob/main/docs/Project%20proposal.pdf</a></p>
</body>
</html>
